{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Check if you're using GPU to accelerate your trainings"},{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The following cells will clone darknet from AlexeyAB's famous repository"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"!git clone https://github.com/AlexeyAB/darknet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adjust the Makefile to enable OPENCV and GPU for darknet and then build darknet"},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd darknet\n!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n!sed -i 's/GPU=0/GPU=1/' Makefile\n!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Verify CUDA version\n****"},{"metadata":{"trusted":true},"cell_type":"code","source":"!/usr/local/cuda/bin/nvcc --version","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Builds darknet so that we can use the darknet executable file to run or train object detectors"},{"metadata":{"trusted":true},"cell_type":"code","source":"!make","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# YOLOv4 has been trained already on the coco dataset which has 80 classes that it can predict. We will grab these pretrained weights so that we can run YOLOv4 on these pretrained classes and get detections."},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# These three functions are helper functions that will allow you to show the image in your Cloud VM after running your detections, as well as upload and download images to and from it"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define helper functions\ndef imShow(path):\n    import cv2\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n\n    image = cv2.imread(path)\n    height, width = image.shape[:2]\n    resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n\n    fig = plt.gcf()\n    fig.set_size_inches(18, 10)\n    plt.axis(\"off\")\n    plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n    plt.show()\n\n# use this to upload files\ndef upload():\n    from google.colab import files\n    uploaded = files.upload() \n    for name, data in uploaded.items():\n    with open(name, 'wb') as f:\n        f.write(data)\n        print ('saved file', name)\n\n# use this to download a file  \ndef download(path):\n    from google.colab import files\n    files.download(path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mount your drive on your cloud VM"},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd ..\nfrom google.colab import drive\ndrive.mount('/content/gdrive')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creation of symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n!ln -s /content/gdrive/My\\ Drive/ /mydrive\n!ls /mydrive","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Copy over both datasets into the root directory of the Colab VM"},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp /mydrive/yolov4/obj.zip ../\n!cp /mydrive/yolov4/test.zip ../","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Unzip the datasets and their contents so that they are now in /darknet/data/ folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip ../obj.zip -d data/\n!unzip ../test.zip -d data/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# This step involves properly configuring your custom .cfg, obj.data, obj.names, train.txt and test.txt files.\n\n# It is important to configure all these files with extreme caution as typos or small errors can cause major problems with your custom training."},{"metadata":{},"cell_type":"markdown","source":"I recommend having batch = 64 and subdivisions = 16 for ultimate results. If you run into any issues then up subdivisions to 32.\n\nMake the rest of the changes to the cfg based on how many classes you are training your detector on.\n\nNote: I set my max_batches = 6000, steps = 4800, 5400, I changed the classes = 1 in the three YOLO layers and filters = 18 in the three convolutional layers before the YOLO layers.\n\nHow to Configure Your Variables:\n\nwidth = 416\n\nheight = 416 (these can be any multiple of 32, 416 is standard, you can sometimes improve results by making value larger like 608 but will slow down training)\n\nmax_batches = (# of classes) * 2000 (but no less than 6000 so if you are training for 1, 2, or 3 classes it will be 6000, however detector for 5 classes would have max_batches=10000)\n\nsteps = (80% of max_batches), (90% of max_batches) (so if your max_batches = 10000, then steps = 8000, 9000)\n\nfilters = (# of classes + 5) * 3 (so if you are training for one class then your filters = 18, but if you are training for 4 classes then your filters = 27)\n\nOptional: If you run into memory issues or find the training taking a super long time. In each of the three yolo layers in the cfg, change one line from random = 1 to random = 0 to speed up training but slightly reduce accuracy of model. Will also help save memory if you run into any memory issues."},{"metadata":{},"cell_type":"markdown","source":"Copy configuration file to root after change it"},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp /mydrive/yolov4/yolov4-obj.cfg ./cfg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a new file within a code or text editor called obj.names where you will have one class name per line in the same order as your classes.txt from the dataset generation step."},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp /mydrive/yolov4/obj.names ./data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# You will also create a obj.data file and fill it with \n1. Number of classes\n2. Path to train.txt\n3. Path to test.txt\n4. Path to Classes.txt\n5. Path to Backup ; This backup path is where we will save the weights to of our model throughout training"},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp /mydrive/yolov4/obj.data  ./data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The last configuration files needed before we can begin to train our custom detector are the train.txt and test.txt files which hold the relative paths to all our training images and valdidation images.\n\nLuckily I have created scripts that eaily generate these two files withe proper paths to all images.\n\nThe scripts can be accessed from the Github Repo\n\nJust download the two files to your local machine and upload them to your Google Drive so we can use them in the Colab Notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp /mydrive/yolov4/generate_train.py ./\n!cp /mydrive/yolov4/generate_test.py ./","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now simply run both scripts to do the work for you of generating the two txt files."},{"metadata":{"trusted":true},"cell_type":"code","source":"!python generate_train.py\n!python generate_test.py","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This step downloads the weights for the convolutional layers of the YOLOv4 network. By using these weights it helps our custom object detector to be way more accurate and not have to train as long. We don't have to use these weights but it will help our model converge and be accurate way faster"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train your custom detector"},{"metadata":{"trusted":true},"cell_type":"code","source":"!./darknet detector train data/obj.data cfg/yolov4-obj.cfg yolov4.conv.137 -dont_show -map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}