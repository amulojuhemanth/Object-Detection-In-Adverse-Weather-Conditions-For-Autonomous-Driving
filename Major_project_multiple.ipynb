{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "from imagecorrection.Airlight import Airlight\n",
    "from imagecorrection.BoundCon import BoundCon\n",
    "from imagecorrection.CalTransmission import CalTransmission\n",
    "from imagecorrection.removeHaze import removeHaze\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import Model\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance\n",
    "# from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = open(r'..\\yolo-coco-data\\coco.names').read().strip().split('\\n')\n",
    "weights_path = r'..\\yolo-coco-data\\yolov4.weights'\n",
    "configuration_path = r'..\\yolo-coco-data\\yolov4.cfg'\n",
    "probability_minimum = 0.5\n",
    "threshold = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = cv2.dnn.readNetFromDarknet(configuration_path, weights_path)\n",
    "layers_names_all = network.getLayerNames()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['yolo_139', 'yolo_150', 'yolo_161']\n"
     ]
    }
   ],
   "source": [
    "layers_names_output = [layers_names_all[i[0] - 1] for i in network.getUnconnectedOutLayers()]  # list \n",
    "print(layers_names_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_model(image_input):\n",
    "    blob = cv2.dnn.blobFromImage(image_input, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    # Check point\n",
    "    blob_to_show = blob[0, :, :, :].transpose(1, 2, 0)\n",
    "    network.setInput(blob)  # setting blob as input to the network\n",
    "    output_from_network = network.forward(layers_names_output)\n",
    "    np.random.seed(42)\n",
    "    colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
    "    bounding_boxes = []\n",
    "    confidences = []\n",
    "    class_numbers = []\n",
    "    image_input_shape = image_input.shape\n",
    "    h, w = image_input_shape[:2]  # Slicing from tuple only first two elements\n",
    "    for result in output_from_network:\n",
    "        for detection in result:\n",
    "            scores = detection[5:]\n",
    "            class_current = np.argmax(scores)\n",
    "            confidence_current = scores[class_current]\n",
    "            if confidence_current > probability_minimum:\n",
    "                box_current = detection[0:4] * np.array([w, h, w, h])\n",
    "                x_center, y_center, box_width, box_height = box_current.astype('int')\n",
    "                x_min = int(x_center - (box_width / 2))\n",
    "                y_min = int(y_center - (box_height / 2))\n",
    "                bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
    "                confidences.append(float(confidence_current))\n",
    "                class_numbers.append(class_current)\n",
    "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n",
    "    pred_scores = []\n",
    "    mean_avg_prec = 0\n",
    "    obj_mean_avg = 0\n",
    "    if len(results) > 0:\n",
    "        for i in results.flatten():\n",
    "            pred_scores.append(confidences[i])\n",
    "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "            colour_box_current = [int(j) for j in colours[class_numbers[i]]]\n",
    "            cv2.rectangle(image_input, (x_min, y_min), (x_min + box_width, y_min + box_height),colour_box_current, 3) \n",
    "    if len(pred_scores) > 0:\n",
    "        mean_avg_prec = sum(pred_scores)/len(results)\n",
    "        obj_mean_avg = len(results) * mean_avg_prec\n",
    "    return image_input, mean_avg_prec, \"detected objects: {}\".format(len(results)), \"No of object detected * Mean Average precision : {}\".format(obj_mean_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isbright(image, dim=50, thresh=0.5):\n",
    "    # Resize image to 50x50\n",
    "    image = cv2.resize(image, (dim, dim))\n",
    "    # Convert color space to LAB format and extract L channel\n",
    "    L, A, B = cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2LAB))\n",
    "    # Normalize L channel by dividing all pixel values with maximum pixel value\n",
    "    L = L/np.max(L)\n",
    "    # Return True if mean is greater than thresh else False\n",
    "    return np.mean(L) > thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-9-33fea8ec5c0a>, line 3)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-33fea8ec5c0a>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    main_dir = r'..\\images-for-testing\\'\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# load image from disk\n",
    "overall_mean_p = []\n",
    "main_dir = r'..\\images-for-testing'\n",
    "for filename in os.listdir(main_dir):\n",
    "    image_path = r'{}\\{}'.format(main_dir, filename)\n",
    "    file_name = image_path.split('\\\\')[-1]\n",
    "    image_input = plt.imread(image_path)\n",
    "\n",
    "    # find if image is bright or dark\n",
    "    select_best_img = {}\n",
    "\n",
    "    plt.figure(figsize=(15.0,15.0))\n",
    "    orginal = detect_model(image_input)\n",
    "    dect = orginal[0]\n",
    "    select_best_img[\"orginal\"] = orginal[3]\n",
    "    im = Image.open(image_path)\n",
    "\n",
    "    enhancer = ImageEnhance.Brightness(im)\n",
    "    factor = 0.5 #darkens the image\n",
    "    im_output_d = enhancer.enhance(factor)\n",
    "    darken = detect_model(np.array(im_output_d))\n",
    "    dect_d = darken[0]\n",
    "    select_best_img[\"darken\"] = darken[3]\n",
    "      \n",
    "\n",
    "    enhancer = ImageEnhance.Brightness(im)\n",
    "    factor = 1.5 #brightens the image\n",
    "    im_output_b = enhancer.enhance(factor)\n",
    "    bright = detect_model(np.array(im_output_b))\n",
    "    dect_b = bright[0]\n",
    "    select_best_img[\"bright\"] = bright[3]\n",
    "       \n",
    "\n",
    "    enhancer = ImageEnhance.Sharpness(im)\n",
    "    factor = 2\n",
    "    img_shrp = enhancer.enhance(factor)\n",
    "    sharp = detect_model(np.array(img_shrp))\n",
    "    dect_s = sharp[0]\n",
    "    select_best_img[\"sharpness\"] = sharp[3]\n",
    "    \n",
    "\n",
    "    enhancer = ImageEnhance.Contrast(im)\n",
    "    factor = 1.5 #increase contrast\n",
    "    im_output_c = enhancer.enhance(factor)\n",
    "    contrast = detect_model(np.array(im_output_c))\n",
    "    dect_c = contrast[0]\n",
    "    select_best_img[\"contrast\"] = contrast[3]\n",
    " \n",
    "\n",
    "    enhancer = ImageEnhance.Sharpness(im_output_d)\n",
    "    factor = 2\n",
    "    img_dshrp = enhancer.enhance(factor)\n",
    "    dark_sharp = detect_model(np.array(img_dshrp))\n",
    "    dect_ds = dark_sharp[0]\n",
    "    select_best_img[\"dark_sharp\"] = dark_sharp[3]\n",
    "\n",
    "    enhancer = ImageEnhance.Brightness(im_output_d)\n",
    "    factor = 1.5 #brightens the image\n",
    "    im_output_b = enhancer.enhance(factor)\n",
    "    dark_bright = detect_model(np.array(im_output_b))\n",
    "    dect_b =dark_bright[0]\n",
    "    select_best_img[\"dark_bright\"] = dark_bright[3]\n",
    "\n",
    "    enhancer = ImageEnhance.Sharpness(im_output_b)\n",
    "    factor = 2\n",
    "    img_bshrp = enhancer.enhance(factor)\n",
    "    bright_sharp = detect_model(np.array(img_bshrp))\n",
    "    dect_bs = bright_sharp[0]\n",
    "    select_best_img[\"bright_sharp\"] = bright_sharp[3]\n",
    "      \n",
    "    enhancer = ImageEnhance.Sharpness(im_output_c)\n",
    "    factor = 2\n",
    "    img_cshrp = enhancer.enhance(factor)\n",
    "    const_sharp = detect_model(np.array(img_cshrp))\n",
    "    dect_cs = const_sharp[0]\n",
    "    select_best_img[\"contrast_sharp\"] = const_sharp[3]\n",
    "  \n",
    "    enhancer = ImageEnhance.Contrast(im_output_b)\n",
    "    factor = 1.5 #increase contrast\n",
    "    im_output_bc = enhancer.enhance(factor)\n",
    "    bright_const = detect_model(np.array(im_output_bc))\n",
    "    dect_bc = bright_const[0]\n",
    "    select_best_img[\"bright_contrast\"] = bright_const[3]\n",
    "\n",
    "    enhancer = ImageEnhance.Color(im)\n",
    "    factor = 1.5\n",
    "    im_output_color = enhancer.enhance(factor)\n",
    "    color = detect_model(np.array(im_output_color))\n",
    "    dect_color = contrast[0]\n",
    "    select_best_img[\"color\"] = color[3]\n",
    "   \n",
    "      \n",
    "    # Estimate Airlight\n",
    "    windowSze = 15\n",
    "    AirlightMethod = 'fast'\n",
    "    A = Airlight(image_input, AirlightMethod, windowSze)\n",
    "\n",
    "    # Calculate Boundary Constraints\n",
    "    windowSze = 3\n",
    "    C0 = 20         # Default value = 20 (as recommended in the paper)\n",
    "    C1 = 300        # Default value = 300 (as recommended in the paper)\n",
    "    Transmission = BoundCon(image_input, A, C0, C1, windowSze)                  #   Computing the Transmission using equation (7) in the paper\n",
    "\n",
    "    # Refine estimate of transmission\n",
    "    regularize_lambda = 1       # Default value = 1 (as recommended in the paper) --> Regularization parameter, the more this  value, the closer to the original patch wise transmission\n",
    "    sigma = 0.7\n",
    "    Transmission = CalTransmission(image_input, Transmission, regularize_lambda, sigma)     # Using contextual information\n",
    "\n",
    "    # Perform DeHazing\n",
    "    HazeCorrectedImg = removeHaze(image_input, Transmission, A, 0.85)\n",
    "    dehaze = detect_model(HazeCorrectedImg)\n",
    "    dect1 = dehaze[0]\n",
    "    select_best_img[\"dehaze\"] = dehaze[3]\n",
    "\n",
    "\n",
    "    better_dect = max(select_best_img, key=select_best_img.get)\n",
    "    best_img_path = r\"C:\\Users\\Sai Krishna\\Desktop\\input\\results\\{}\".format(file_name)\n",
    "    if not better_dect:\n",
    "        print('no object is dected in given image')\n",
    "    elif better_dect == 'orginal':\n",
    "        overall_mean_p.append(orginal[1])\n",
    "        # plt.imsave(best_img_path, orginal[0])\n",
    "    elif better_dect == 'darken':\n",
    "        overall_mean_p.append(darken[1])\n",
    "        # plt.imsave(best_img_path, darken[0])\n",
    "    elif better_dect == 'bright':\n",
    "        overall_mean_p.append(bright[1])\n",
    "        # plt.imsave(best_img_path, bright[0])\n",
    "    elif better_dect == 'sharpness':\n",
    "        overall_mean_p.append(sharp[1])\n",
    "        # plt.imsave(best_img_path, sharp[0])\n",
    "    elif better_dect == 'contrast':\n",
    "        overall_mean_p.append(contrast[1])\n",
    "        # plt.imsave(best_img_path, contrast[0])\n",
    "    elif better_dect == 'dark_sharp':\n",
    "        overall_mean_p.append(dark_sharp[1])\n",
    "        # plt.imsave(best_img_path, dark_sharp[0])\n",
    "    elif better_dect == 'dark_bright':\n",
    "        overall_mean_p.append(dark_bright[1])\n",
    "        # plt.imsave(best_img_path, dark_bright[0])   \n",
    "    elif better_dect == 'bright_sharp':\n",
    "        overall_mean_p.append(bright_sharp[1])\n",
    "        # plt.imsave(best_img_path, bright_sharp[0])\n",
    "    elif better_dect == 'contrast_sharp':\n",
    "        overall_mean_p.append(const_sharp[1])\n",
    "        # plt.imsave(best_img_path, const_sharp[0])\n",
    "    elif better_dect == 'bright_contrast':\n",
    "        overall_mean_p.append(bright_const[1])\n",
    "        # plt.imsave(best_img_path, bright_const[0])\n",
    "    elif better_dect == 'color':\n",
    "        overall_mean_p.append(color[1])\n",
    "        # plt.imsave(best_img_path, color[0])\n",
    "    elif better_dect == 'dehaze':\n",
    "        overall_mean_p.append(dehaze[1])\n",
    "        # plt.imsave(best_img_path, dehaze[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overall Mean avg precision value 0.9177902638912201\n"
     ]
    }
   ],
   "source": [
    "print('Overall Mean avg precision value {}'.format(sum(overall_mean_p)/len(overall_mean_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd0e922dd073470bdcc017ae3abd31d6491d6ed7bf31c1d559806e5511bfea88b81",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}